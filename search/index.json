[{"content":"强化学习 DPO方法与RLHF不同之处在于，DPO方法利用成对数据，舍弃了有关RM模型的训练，并且训练过程为监督学习，因此不需要PPO等强化学习方法。\n关于DPO的许多变体：\n1、数据形式改进\na. KTO (Kahneman–Tversky Optimization)\nDPO的优化基于Bradley–Terry偏好模型，而KTO基于行为经济学的前景理论，通过设置阈值r直接反映答案的好坏。KTO只需要单点数据，并且结果更加可靠，缺点是其同样只能给出对输入结果好/坏的二元评价。该模型适合风险敏感场景（如金融/医疗）等领域。\nb. IPO (Identity Preference Optimization)\nIPO在DPO的基础上去掉了π_ref项，改写log-odds型，在许多环境下训练更稳定。\nc. DPOP (DPO with Probability calibration)\n在 DPO 的基础上，加一个正例 log-likelihood 最大化项，使模型学习更多正面案例。\nd. sDPO (Stepwise DPO)\n在DPO基础上优化函数不变，但每过n步会将当前模型结果设置为新的ref模型，从而减少模型的限制。\ne. RPO (Rank Preference Optimization)\nDPO通过成对数据训练，而RPO可以利用多个排序后的数据进行训练。\n2、优化目标改进\na. ORPO (Odds Ratio Preference Optimization)\n使用几率比替换DPO中的log-odds算法，更好地对齐“好/坏”的相对概率，理论上对类别不平衡更稳健。\nb. XPO (Exploratory Preference Optimization)\nXPO是一个综合框架，使得输入数据既可以是DPO的成对数据，KTO的单个数据，也可以是RPO的多个数据。\nc. CPO (Conditional Preference Optimization)\nCPO为偏好数据增加了约束，例如问题“今天天气如何？”在晴天条件下“今天晴天”的偏好度更高，而非DPO中“晴天”和“雨天”的回答全部成立。\nd. FDPO (Filtered / Fast DPO)\nFDPO 在训练时加入数据筛选或高效近似，提升训练效率牺牲部分精度换取速度和大规模训练可行性。\n3、精度改进\na. TDPO (Token-level DPO)\n将偏好的选择范围从句子扩展到句子中的token，计算量更大但结果更优。\n","date":"2025-09-12T00:00:00Z","image":"https://starrydreamawa.github.io/hugo-stack.github.io/p/250912/title_hu_451dba501f2a05f4.jpg","permalink":"https://starrydreamawa.github.io/hugo-stack.github.io/p/250912/","title":"250912"},{"content":"概率论 一到n维我就懵\n记一道例题吧\n有$N$个顾客，每个顾客消费数量为$X_i$，且$N$与$X_i$之间相互独立，求平均营业额$X$。 $$\\begin{aligned} X \u0026= E(\\sum_{i=1}^NX_i) \\\\ \u0026= \\sum_n^{\\infty} E(\\sum_{i=1}^nX_i | N=n)P(N=n) \\space 由相互独立得\\\\ \u0026= \\sum_n^{\\infty} nEX_iP(N=n) \\\\ \u0026= EX_i\\sum_n^{\\infty}nP(N=n) \\\\ \u0026= EX_iEN \\\\ \\end{aligned}$$公式都能看懂，就是不会做题\n下面这位更是公式也看不懂\n矩阵 矩阵A的值域/列空间R(A)是对任意能乘的x，Ax的空间\n矩阵A的零空间/化零子空间N(A)是零Ax=0的所有x的空间\ndeepseek：矩阵A是烤面包机，R(A)是它能烤出的所有面包，N(A)是它不能处理（输出为0）的所有原料组合\n$\\alpha$和$\\beta$是V1和V2的基，T是V1→V2上的线性映射，且T在$\\alpha$和$\\beta$下的矩阵是A，V1中向量$\\xi$在$\\alpha$基下坐标是$x$，V2中向量$\\eta$在$\\beta$基下坐标是$y$，则$\\xi$是R(T)的基的充要条件是$x$是R(A)的基，$\\eta$是N(T)的基的充要条件是$y$是N(A)的基\ndeepseek：V1、V2是两种语言，$\\alpha$和$\\beta$是组成两种语言的符号集合（比如abc\u0026hellip;z和五十音），T是翻译官，A是翻译对照表，$\\xi$和$\\eta$是两种语境下的两个句子的表示。\n那么$\\xi$是R(T)的基，意为T$\\xi$能表示所有V2的句子，即$x$变换后能翻译出任何V2的句子;\n$\\eta$是N(T)的基，意为$\\eta$囊括了所有T翻不出来的句子，即$y$不是V1经过T能翻译过来的句子。\n个人理解：这个定理就是用来说明映射T和矩阵A之间的关系的\n子空间的交要列方程求，很麻烦；子空间的并就是把子空间的向量拼到一起，然后行最简形主元所在原列就是基，个数就是维数\n不是主元的那些列就是交空间的基，个数就是维数。或者可以通过$Dim(V_1\\subset V2)+Dim(V_1+V_2) = DimV_1 + DimV_2$求维数而减少化简量。\n求有条件的子空间维度和基，化简出很多线性无关的向量当基然后数个数就行了\n比如$C(t)= a_0+a_1t+\\dots+a_{n-1}t^{n-1} | C(1)=0$，化简能变成$t^i-1$表示，这就是基，维数就是n-1。\n太难了\u0026hellip;\n网站建设 新增了一个链接，通向另一个准备建设的网站\n一开始打算做一个需要密码才能访问的隐藏空间，不过一来在框架之上修改很难，二来显得我不够热情\n于是就把链接挂在很显眼的地方了\n不知道会不会有人被里面的内容吓到呢？\n","date":"2025-09-11T00:00:00Z","image":"https://starrydreamawa.github.io/hugo-stack.github.io/p/250911/title_hu_e2c326744dbe530c.jpg","permalink":"https://starrydreamawa.github.io/hugo-stack.github.io/p/250911/","title":"250911"},{"content":"矩阵论 判断两个集合相等需要证明$A \\subseteq B$且$B \\subseteq A$ 向量构成矩阵是按列排布的，别写反了T_T\n论文写作 开源论文网站 有了idea可以先乱写放arxiv预印本平台之后再补\n影响因子（IF）：前N年发表论文被引次数/前N年发表论文数，小于0.1会被踢\n中科院A区含金量高（和我真的有关系吗\u0026hellip;）\nsci-hub绕过所有科研论文收费，可以免费找论文\\\n读论文建议记笔记\n论文解决什么问题？\n用了什么方法？\n达到什么效果？\n精读：每个段讲了什么？\n创新点、关键点、启发点\\\n写论文相关： 在总结之前尽量不要用“了”表示完成时\nacknowledgements可以让老师写\n参考文献尊重时效性和质量，尽量凑5的整数\n","date":"2025-09-10T00:00:00Z","image":"https://starrydreamawa.github.io/hugo-stack.github.io/p/250910/title_hu_6c6f05c58307148b.jpg","permalink":"https://starrydreamawa.github.io/hugo-stack.github.io/p/250910/","title":"250910"},{"content":"导论 额\u0026hellip;要写好Log？\n随机过程（概率论） 上来就被montmort问题搞懵了，知道答案后（这里有详细描述）明白了几件非常重要的事\nn个人的帽子混成一团然后随机拿，对每个人而言，拿到自己帽子的概率$I_i$都是$\\frac{1}{n}$\n两个人都拿到自己帽子的概率$P(I_iI_j) = \\frac{1}{n(n-1)}$,同理n个人都拿到的概率是$\\frac{1}{n!}$ 而所有人都没拿到自己帽子的概率是$1-P(\\cup I_i)$，由加法公式可得 $$ P(\\cup I_i) = \\sum P(I_i) - \\sum P(I_iI_j) + \\cdots + (-1)^{n-1}P(\\cap I_i) \\\\ = C_n^1\\cdot \\frac{1}{n} - C_n^2\\frac{1}{n(n-1)} + \\cdots + C_n^n\\frac{1}{n!} \\\\ = \\sum_{k=1}^n \\frac{(-1)^{k-1}}{k!} $$ 剩下的就比较简单了\n拼尽全力勉强想起八大分布：0-1分布（伯努利分布）、二项分布B($n,q$)、均匀分布U($a,b$)、指数分布E($\\lambda$)、泊松分布P($\\lambda$)、正态分布N($\\mu,\\sigma$)\n\u0026hellip;\u0026hellip;还有单点分布$P(X=C)=1$，以及几何分布和超几何分布，但后俩跟今天的没关系，嗯\n然后：这个特征函数$\\phi(t)=E(e^{jtx})$（是$jtx$不是$\\pi x$！！！）怎么涉及复数函数求导啊？\\\n于是问了一下deepseek。ds：你可以看到，这非常类似于傅里叶变换。\n傅里叶变换啊，我大三研究了两周没搞懂就放弃了，怎么还在追我\n于是去查了傅里叶变换，发现和欧拉公式有关\n于是去查了欧拉公式，发现和泰勒展开有关\n于是终于找到自己会的了：把$e^x$的$x$替换成$i\\theta$展开，把$i$的幂求出，得到的公式恰好是$\\sin\\theta + \\cos\\theta$的展开，因此\n$e^{i\\theta} = \\sin\\theta + \\cos\\theta$\n然后傅里叶变换就是 $$ F(\\omega) = \\int_{-\\infty}^{+\\infty}f(t)e^{-i\\omega t}dt $$ 要求什么函数的往里代就行\n回到正题，绕了一圈发现带虚数的函数把$i,j$当成常数正常求导就行了\n然后把七种分布的特征函数都求了一遍，感觉微积分也都快扔完了，之后做题补一补吧\n特征函数最重要的性质是 $$ \\phi^{(k)}(0)=j^kEX^k, k\\le n $$ 可以用来求X的n阶矩\n矩阵论 完全跟不上了，之后做题补习吧\n落下的内容：第一章习题、QR变换、合同/相似相关的内容\u0026hellip;\n计算机体系结构 计算机性能不能只看硬件指数，平均性能一般只能达到峰值性能的5%到30%。\n指示码优化：将数据的一部分位作为指示码，用来指示数据类型、数据是否存活等。例如指针4位对齐，就可以用最低两位存放\u0026quot;这是指针\u0026quot;的编码\n要学会提问题，才能有所收获\n","date":"2025-09-09T00:00:00Z","image":"https://starrydreamawa.github.io/hugo-stack.github.io/p/250909/title_hu_d136117ad532eb86.jpg","permalink":"https://starrydreamawa.github.io/hugo-stack.github.io/p/250909/","title":"250909"},{"content":"矩阵论部分 关于线性空间的判定：\n在证明是线性空间时需要列出8条定义，但证明不是的时候基本只要看对加法、数乘不封闭或无零元即可\n关于数乘：常数是额外指定的，通常为实数，不是线性空间里的内容\n例：所有n次多项式关于普通多项式的加法和数乘构成的空间$V$：\n设$A = x^n, B = -x^n$，显然$A, B \\in V$，但$A+B=0 \\notin V$，因此对加法不封闭，不是线性空间\n求$A^{-1}B$的时候，设$A^{-1}B = X$，则$AX = B$，所以可以写出增广矩阵$[A|B]$然后行变换成为$[E|A^{-1}B]$求出结果。\n代码部分 遵循老师“有计算机就别手算矩阵”的教诲，寻找了计算机计算矩阵的方式\n使用numpy可求逆矩阵\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 import numpy as np def matrix_invert(A: np.ndarray): try: A_inv = np.linalg.inv(A) print(\u0026#34;\\n逆矩阵:\u0026#34;) print(A_inv) except np.linalg.LinAlgError: print(\u0026#34;\\n该矩阵不可逆\u0026#34;) A = np.array([ [1, 2, 1], [2, 4, 0], [3, 7, 2],]) matrix_invert(A) 逆矩阵: [[ 4. 1.5 -2. ] [-2. -0.5 1. ] [ 1. -0.5 0. ]] 使用sympy可得行最简形矩阵+主元列\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 import sympy as sp def matrix_simplify(A: np.ndarray): A_sym = sp.Matrix(A) # 转换成 sympy 矩阵 rref_matrix, pivot_cols = A_sym.rref() print(\u0026#34;\\n行最简形矩阵:\u0026#34;) sp.pprint(rref_matrix) print(\u0026#34;主元列:\u0026#34;, pivot_cols) A = np.array([[1, 1, -1, -1, 2, 0, -2, 1], [2, -1, 2, -1, 1, 1, 1, 3], [-1, 1, 1, 0, 0, 2, 1, 1], [0, 1, 1, 1, 1, 2, 2, 2]]) matrix_simplify(A) 行最简形矩阵: ⎡1 0 0 0 1 0 0 1⎤ ⎢ ⎥ ⎢0 1 0 0 1 1 0 1⎥ ⎢ ⎥ ⎢0 0 1 0 0 1 1 1⎥ ⎢ ⎥ ⎣0 0 0 1 0 0 1 0⎦ 主元列: (0, 1, 2, 3) 没了 呜呜呜\n","date":"2025-09-08T00:00:00Z","image":"https://starrydreamawa.github.io/hugo-stack.github.io/p/250908/title_hu_2d88e15cbb737e24.jpg","permalink":"https://starrydreamawa.github.io/hugo-stack.github.io/p/250908/","title":"250908"},{"content":"我会写标题啦 我会写正文啦💡\n而且还会打数学符号 $\\sum_k^n \\alpha_k\\sin\\theta_k$\n还有超链接\n甚至还会加图片\n以后要加油呀\n","date":"2025-09-07T00:00:00Z","image":"https://starrydreamawa.github.io/hugo-stack.github.io/p/250907/title_hu_10766f6904a726b0.png","permalink":"https://starrydreamawa.github.io/hugo-stack.github.io/p/250907/","title":"250907"}]